# ğŸ“š TP - PrÃ©traitement des DonnÃ©es Textuelles en NLP

## ğŸ¯ Objectifs du TP

Ce travail pratique vous guidera Ã  travers toutes les Ã©tapes essentielles du prÃ©traitement de texte pour le Natural Language Processing (NLP), de la base jusqu'aux techniques avancÃ©es de Deep Learning.

**Ã€ la fin de ce TP, vous saurez :**
- âœ… Nettoyer et normaliser des donnÃ©es textuelles brutes
- âœ… Tokeniser et crÃ©er des n-grammes
- âœ… Appliquer la rÃ©duction linguistique (stemming, lemmatisation)
- âœ… Utiliser les techniques POS tagging et NER
- âœ… PrÃ©parer des donnÃ©es pour le Deep Learning (padding, troncature)
- âœ… Augmenter artificiellement vos datasets textuels
- âœ… Comprendre les bases de la transformation numÃ©rique

---

## ğŸ“‹ PrÃ©requis

### Connaissances requises
- Python de base (variables, boucles, fonctions)
- Manipulation de donnÃ©es avec Pandas (niveau basique)
- Notions de base en Data Science

### Logiciels nÃ©cessaires
- Python 3.8 ou supÃ©rieur
- Jupyter Notebook ou JupyterLab
- Connexion internet (pour tÃ©lÃ©charger les ressources NLTK et spaCy)

---

## ğŸš€ Installation

### Ã‰tape 1 : Cloner ou tÃ©lÃ©charger le projet

```bash
# Si vous utilisez Git
git clone [URL_DU_REPO]
cd tp-nlp-preprocessing

# Ou tÃ©lÃ©chargez simplement le dossier ZIP et extrayez-le
```

### Ã‰tape 2 : CrÃ©er un environnement virtuel (recommandÃ©)

```bash
# Sur Windows
python -m venv venv
venv\Scripts\activate

# Sur macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### Ã‰tape 4 : TÃ©lÃ©charger les modÃ¨les et ressources

```bash
# TÃ©lÃ©charger les ressources NLTK
python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt'); nltk.download('wordnet'); nltk.download('averaged_perceptron_tagger'); nltk.download('omw-1.4')"

# TÃ©lÃ©charger les modÃ¨les spaCy
python -m spacy download fr_core_news_sm
python -m spacy download en_core_web_sm
```

### Ã‰tape 5 : Lancer Jupyter Notebook

```bash
jupyter notebook
```

Ouvrez ensuite le fichier `tp_nlp_preprocessing.ipynb` dans votre navigateur.

---

## ğŸ“– Structure du TP

Le notebook est organisÃ© en **8 parties progressives** :

### ğŸ”§ **Partie 1 : Nettoyage de Base**
- Suppression HTML, URLs, emails
- Gestion des Ã©mojis et Ã©moticÃ´nes
- Suppression de la ponctuation
- **Bonus** : MÃ©thodes alternatives professionnelles

### ğŸ“ **Partie 2 : Normalisation et Harmonisation**
- Conversion en minuscules
- Gestion des contractions
- DÃ©tection de langue

### ğŸ”¤ **Partie 3 : Tokenisation et N-grammes**
- Segmentation en phrases
- Tokenisation en mots
- GÃ©nÃ©ration de 1-grammes, 2-grammes, 3-grammes

### âœ‚ï¸ **Partie 4 : RÃ©duction Linguistique**
- Suppression des stop words
- Stemming (racinisation)
- Lemmatisation
- Comparaison des techniques

### ğŸ¯ **Partie 5 : Techniques AvancÃ©es**
- POS Tagging (Ã©tiquetage grammatical)
- Reconnaissance d'EntitÃ©s NommÃ©es (NER)
- Gestion des mots Ã  faible frÃ©quence

### ğŸ”„ **Partie 6 : Pipeline Complet**
- Classe `PreprocesseurTexte` rÃ©utilisable
- Pipeline end-to-end
- Exemple d'application pratique

### ğŸ§  **Partie 7 : PrÃ©traitement Deep Learning**
- **Padding** : uniformiser les longueurs
- **Troncature** : limiter les sÃ©quences longues
- **Augmentation de donnÃ©es** :
  - Substitution de synonymes
  - RÃ©tro-traduction
  - Insertion/suppression alÃ©atoire
- Pipeline complet pour rÃ©seaux de neurones

### ğŸ“Š **Partie 8 : Transformation NumÃ©rique (AperÃ§u)**
- Introduction Ã  Bag of Words
- Introduction Ã  TF-IDF
- *(Word Embeddings seront couverts dans un cours dÃ©diÃ©)*

---

## ğŸ’¡ Conseils d'utilisation

### Pour les dÃ©butants
1. **Suivez l'ordre des cellules** : Le notebook est conÃ§u pour Ãªtre progressif
2. **ExÃ©cutez chaque cellule** : Utilisez `Shift + Enter` pour exÃ©cuter et passer Ã  la suivante
3. **Lisez les commentaires** : Chaque section est bien documentÃ©e
4. **ExpÃ©rimentez** : Modifiez les exemples avec vos propres textes

### Pour les utilisateurs avancÃ©s
- Explorez les **mÃ©thodes alternatives** prÃ©sentÃ©es
- Testez les fonctions avec vos propres datasets
- Adaptez la classe `PreprocesseurTexte` Ã  vos besoins spÃ©cifiques
- Combinez plusieurs techniques pour crÃ©er votre pipeline personnalisÃ©

---

## ğŸ” Exemples de donnÃ©es utilisÃ©es

Le TP utilise des exemples variÃ©s et concrets :
- Textes en franÃ§ais et en anglais
- Exemples de rÃ©seaux sociaux (Ã©mojis, URLs)
- Citations littÃ©raires (Stephen King)
- Textes d'actualitÃ© (Apple, Steve Jobs)
- Phrases Star Wars (pour les n-grammes)

---

## ğŸ“Š RÃ©sultats attendus

AprÃ¨s avoir complÃ©tÃ© ce TP, vous serez capable de :

```python
# Exemple de pipeline complet
preprocesseur = PreprocesseurTexte(langue='french')

texte_brut = "Bonjour! ğŸ˜€ Visitez https://example.com pour + d'infos!!!"
tokens_propres = preprocesseur.pretraiter(texte_brut)

print(tokens_propres)
# Output: ['bonjour', 'visiter', 'info']
```

---

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨me : Erreur lors du tÃ©lÃ©chargement des modÃ¨les spaCy
```bash
# Solution : Utiliser pip au lieu de python -m
pip install https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl
```

### ProblÃ¨me : Module 'contractions' introuvable
```bash
pip install contractions
```

### ProblÃ¨me : Erreur avec TensorFlow
```bash
# Pour les systÃ¨mes plus anciens, utilisez une version antÃ©rieure
pip install tensorflow==2.13.0
```

### ProblÃ¨me : Jupyter ne trouve pas le kernel
```bash
python -m ipykernel install --user --name=venv
```

---

## ğŸ“š Ressources complÃ©mentaires

### Documentation officielle
- [NLTK Documentation](https://www.nltk.org/)
- [spaCy Documentation](https://spacy.io/)
- [TensorFlow Text](https://www.tensorflow.org/text)
- [Scikit-learn Text Feature Extraction](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)

### Tutoriels recommandÃ©s
- [NLTK Book](https://www.nltk.org/book/)
- [spaCy Course](https://course.spacy.io/)
- [Hugging Face NLP Course](https://huggingface.co/course/)

### BibliothÃ¨ques avancÃ©es (optionnelles)
- **nlpaug** : Augmentation de donnÃ©es avancÃ©e
- **textaugment** : Plus de techniques d'augmentation
- **transformers** : Pour aller vers BERT, GPT, etc.

---

## ğŸ¤ Contribution

Si vous trouvez des erreurs ou souhaitez amÃ©liorer ce TP :
1. CrÃ©ez une issue pour signaler le problÃ¨me
2. Proposez une pull request avec vos amÃ©liorations
3. Partagez vos retours d'expÃ©rience

---

## ğŸ“ Notes importantes

### âš ï¸ Limitations du TP
- La **transformation numÃ©rique** (Partie 8) est volontairement succincte
- Les **word embeddings** (Word2Vec, GloVe, FastText) seront couverts dans un cours dÃ©diÃ©
- Certaines bibliothÃ¨ques d'augmentation avancÃ©e sont optionnelles

### ğŸ’¾ DonnÃ©es et vie privÃ©e
- N'utilisez pas de donnÃ©es sensibles ou personnelles dans ce TP
- Les exemples fournis sont fictifs ou issus du domaine public

---

## ğŸ“ Auteur et Contexte

Ce TP accompagne un exposÃ© sur le prÃ©traitement de texte en NLP et est conÃ§u pour des Ã©tudiants ayant :
- âœ… Des bases solides en analyse de donnÃ©es tabulaires
- âœ… Des notions de Data Science
- âœ… Une volontÃ© d'apprendre le NLP progressivement

**Objectif pÃ©dagogique** : Montrer que le NLP n'est pas difficile quand on progresse Ã©tape par Ã©tape ! ğŸš€

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consultez la section **DÃ©pannage** ci-dessus
2. VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es
3. Relisez les commentaires dans le notebook
4. Recherchez l'erreur dans la documentation officielle

---

## ğŸ“… Temps estimÃ©

- **Installation** : 15-30 minutes
- **Parties 1-3** : 1h30
- **Parties 4-6** : 2h00
- **Partie 7** (Deep Learning) : 1h30
- **Partie 8** (AperÃ§u) : 30 minutes

**Total** : ~5-6 heures pour une comprÃ©hension approfondie

---

## âœ… Checklist de progression

Cochez au fur et Ã  mesure :

- [ ] Installation complÃ¨te et fonctionnelle
- [ ] Partie 1 : Nettoyage de base maÃ®trisÃ©
- [ ] Partie 2 : Normalisation comprise
- [ ] Partie 3 : Tokenisation et n-grammes OK
- [ ] Partie 4 : Stemming vs Lemmatisation clair
- [ ] Partie 5 : POS et NER expÃ©rimentÃ©s
- [ ] Partie 6 : Pipeline complet testÃ©
- [ ] Partie 7 : Techniques Deep Learning pratiquÃ©es
- [ ] Partie 8 : AperÃ§u transformation numÃ©rique vu
- [ ] Exercice final rÃ©alisÃ©
- [ ] TestÃ© avec mes propres donnÃ©es

---

## ğŸ‰ FÃ©licitations !

Une fois ce TP terminÃ©, vous aurez acquis des compÃ©tences solides en prÃ©traitement de texte, une Ã©tape qui reprÃ©sente 60-80% du travail dans un projet NLP rÃ©el !

**Prochaine Ã©tape** : Approfondir la transformation numÃ©rique et les word embeddings dans le cours dÃ©diÃ©.

---

*Bon apprentissage ! ğŸ“–âœ¨*